{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r ../requirements.txt\n",
    "# %pip install --quiet --upgrade  langchain langchain-community langchainhub gpt4all chromadb bs4 torch transformers\n",
    "# !pip freeze >> ../requirements.txt\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings, GPT4AllEmbeddings, BedrockEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import LlamaCpp, Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnablePick\n",
    "\n",
    "from chromadb.errors import InvalidDimensionException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file : Buggy News_part_0\n",
      "Using file : history_of_cmu_part_0\n",
      "Using file : program_handbooks_part_5000\n",
      "Using file : lti_papers_metadata_part_0\n",
      "Using file : program_handbooks_part_0\n",
      "Using file : academic_calendars_part_0\n",
      "Using file : About Scottie_part_0\n",
      "Using file : Tartan Facts_part_0\n",
      "Using file : lti_faculty_part_0\n",
      "Using file : history_of_scs_part_0\n",
      "Using file : Kiltie Band_part_0\n",
      "Using file : lti_programs_part_0\n",
      "Splitting Text\n",
      "Splitting Text Done\n",
      "Creating Chroma\n",
      "Done Creating Chroma\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "BASE_DIR = '/home/raj/nlp/cmu-rag/data/documents/combined_txt_files_length_normalized/'\n",
    "# relevant_files = ['l']\n",
    "\n",
    "docs = []\n",
    "for file in os.listdir(BASE_DIR):\n",
    "    # print(file)\n",
    "    if \"schedule\" in file:\n",
    "        continue\n",
    "    print(\"Using file :\", file)\n",
    "    loader = TextLoader(BASE_DIR + file)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "print(\"Splitting Text\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(\"Splitting Text Done\")\n",
    "\n",
    "try:\n",
    "    print(\"Creating Chroma\")   \n",
    "    vectorstore = Chroma.from_documents(documents=all_splits, embedding=OllamaEmbeddings())\n",
    "except InvalidDimensionException:\n",
    "    print(\"Deleting Chroma\")\n",
    "    Chroma().delete_collection()\n",
    "    print(\"Creating Chroma afresh\")\n",
    "    vectorstore = Chroma.from_documents(documents=all_splits, embedding=OllamaEmbeddings())\n",
    "print(\"Done Creating Chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Answer questions on CMU from these documents\"\n",
    ")\n",
    "\n",
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "rag_prompt_llama = hub.pull(\"rlm/rag-prompt-llama\")\n",
    "prompt = rag_prompt_llama\n",
    "# print(prompt.messages)\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Whom should I contact for additional info on the MCDS program?', 'How many semesters does the MS AI program generally consist of ?']\n",
    "\n",
    "ex = qa_chain.invoke(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first question, \"Whom should I contact for additional info on the MCDS program?\", you can reach out to the McMaster University Graduate Studies office or visit their website for more information. They have a dedicated team for handling inquiries and can provide you with the most up-to-date and accurate information about the program.\n",
      "\n",
      "For the second question, \"How many semesters does the MS AI program generally consist of?\", the answer is generally two to three semesters, depending on the student's academic background and the course load they take on. It's best to consult with the program advisor or check the university's website for the most accurate information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ex)\n",
    "type(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(persist_directory=\"./chroma_db\", embedding_function=OllamaEmbeddings())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmu_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
