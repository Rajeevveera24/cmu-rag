{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (0.1.9)\n",
      "Requirement already satisfied: langchain-community in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (0.0.24)\n",
      "Requirement already satisfied: langchainhub in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (0.1.14)\n",
      "Requirement already satisfied: gpt4all in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (2.2.1.post1)\n",
      "Requirement already satisfied: chromadb in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (0.4.23)\n",
      "Requirement already satisfied: bs4 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (0.1.26)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (0.1.8)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (2.6.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchainhub) (2.31.0.20240218)\n",
      "Requirement already satisfied: tqdm in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from gpt4all) (4.66.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (1.0.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (0.110.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.27.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (1.17.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (1.23.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (1.62.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from chromadb) (3.9.15)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: packaging>=19.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.28.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (4.3.0)\n",
      "Requirement already satisfied: coloredlogs in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.23.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/raj/anaconda3/envs/cmu_rag/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade  langchain langchain-community langchainhub gpt4all chromadb bs4\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loader downloaded\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "\n",
    "print(\"loader downloaded\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings, GPT4AllEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OllamaEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /Users/rlm/miniforge3/envs/llama/bin/pip: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade --quiet  llama-cpp-python\n",
    "\n",
    "!CMAKE_ARGS=\"-DLLAMA_METAL=on\" FORCE_CMAKE=1 /Users/rlm/miniforge3/envs/llama/bin/pip install -U llama-cpp-python --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[The stage is set for a rap battle between Stephen Colbert and John Oliver. The crowd is energized and ready to witness a epic battle of wits and rhymes. Both contestants take their places at the mic, and the battle begins.]\\n\\nStephen Colbert: Yo, John, it's on! I'm the king of satire,\\nWith biting jokes that leave you in a state of dire.\\nI'll take on your fake British accent any day,\\nAnd show you how to really rap like a pro in every way.\\n\\nJohn Oliver: Hold up, Colbert, don't get too cocky,\\nI may not have your experience, but I've got the flow.\\nMy rhymes are tight and my delivery is smooth,\\nAnd by the end of this battle, you'll know who's in the room.\\n\\nStephen Colbert: Oh, really? Well let me tell you something,\\nI may not be as tall as you, John, but I've got the magic.\\nMy rhymes are fire and my flow is sick,\\nAnd when it comes to wit, I'm the one who's quick.\\n\\nJohn Oliver: You may have the witty words, Colbert, but I've got the skills,\\nI can rap about anything, from politics to thrills.\\nMy rhymes are clever and my flow is fresh,\\nAnd when it comes to a battle, I'm the one who's blessed.\\n\\nStephen Colbert: Oh, John, you may have your tricks up your sleeve,\\nBut when it comes to satire, I'm the master of the belt.\\nMy jokes are biting and my wit is sharp,\\nAnd by the end of this battle, you'll see who's in the dark.\\n\\nJohn Oliver: Not so fast, Colbert, let me show you my stuff,\\nI may not have your experience, but I've got the clout.\\nMy rhymes are tight and my flow is smooth,\\nAnd when it comes to a battle, I'm the one who's proof.\\n\\n[The rap battle continues with both contestants delivering clever and witty rhymes, each trying to outdo the other. The crowd is on their feet, cheering and chanting for their favorite.]\\n\\nStephen Colbert: And there you have it, John, I've shown you my skill,\\nI may not be as tall as you, but I'm the king of the thrill.\\nMy rhymes are fire and my flow is sick,\\nAnd when it comes to a battle, I'm the one who's quick.\\n\\nJohn Oliver: Not so fast, Colbert, let me show you my stuff,\\nI may not have your experience, but I've got the clout.\\nMy rhymes are tight and my flow is smooth,\\nAnd when it comes to a battle, I'm the one who's proof.\\n\\n[The rap battle ends with both contestants delivering their final lines, leaving the crowd in awe of their skill and wit.]\\n\\nStephen Colbert: Well, John, it looks like we've reached the end,\\nBut don't be sad, my friend, for this was just a trend.\\nI may not have won the battle, but I've shown you my skill,\\nAnd when it comes to satire, I'm the one who's in control.\\n\\nJohn Oliver: Not so fast, Colbert, let me show you my might,\\nI may not have your experience, but I've got the clout tonight.\\nMy rhymes are tight and my flow is smooth,\\nAnd when it comes to a battle, I'm the one who's proof.\\n\\n[The crowd cheers and applauds as both contestants take their bows and exit the stage.]\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp, Ollama\n",
    "\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=\"/Users/rlm/Desktop/Code/llama.cpp/models/llama-2-13b-chat.ggufv3.q4_0.bin\",\n",
    "#     n_gpu_layers=n_gpu_layers,\n",
    "#     n_batch=n_batch,\n",
    "#     n_ctx=2048,\n",
    "#     f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "#     verbose=True,\n",
    "# )\n",
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "llm.invoke(\"Simulate a rap battle between Stephen Colbert and John Oliver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main themes in these retrieved documents are:\\n\\n1. Sensory Memory: This theme is focused on the earliest stage of memory, which allows individuals to retain impressions of sensory information (visual, auditory, etc.) after the original stimuli have ended. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n2. Tool Use: This theme encompasses the use of tools to augment large language models, such as ChemCrow, which allows for chemistry tools to be used with these models, and Scientific Discovery Agent, a generative agent simulation that demonstrates the potential for large language models to perform scientific discovery tasks. Other proof-of-concept examples include Generative Agents Simulation and Emergent Autonomous Scientific Research Capabilities of Large Language Models.\\n3. Component Three: Tool Use - Case Studies, Challenges, Citation, and References. This section provides detailed information on the tool use aspect of the architecture, including case studies, proof-of-concept examples, challenges, and references.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "rag_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, there are several approaches to task decomposition in AI research. These include:\\n\\n1. Generative Agents Simulation: This approach involves using large language models (LLMs) to simulate scientific discovery and proof-of-concept examples. Tools such as API-Bank and HuggingGPT have been developed to augment LLMs with chemistry tools and solve AI tasks, respectively.\\n2. Scientific Discovery Agent: This approach involves using LLMs to perform scientific discovery and research. Tools such as ChemCrow have been developed to augment LLMs with chemistry tools for emergent autonomous scientific research capabilities.\\n3. Proof-of-Concept Examples: This approach involves using LLMs to demonstrate the feasibility of certain AI tasks or applications. For example, Boiko et al. (2023) demonstrated the ability of large language models to perform scientific research independently.\\n\\nIt is important to note that these approaches are not mutually exclusive, and they can be combined in various ways to achieve different goals. However, the specific approach used will depend on the particular task or application being addressed.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnablePick\n",
    "\n",
    "# Chain\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=RunnablePick(\"context\") | format_docs)\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"[INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \\nQuestion: {question} \\nContext: {context} \\nAnswer: [/INST]\"))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "rag_prompt_llama = hub.pull(\"rlm/rag-prompt-llama\")\n",
    "rag_prompt_llama.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the approaches to Task Decomposition?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complex task into smaller, more manageable subtasks. There are several approaches to task decomposition, including:\\n\\n1. Functional decomposition: This involves breaking down a task into its individual functions or subtasks, each with a specific function or outcome.\\n2. Component decomposition: This involves breaking down a task into its component parts or modules, each with a specific function or role in the overall task.\\n3. Workflow decomposition: This involves breaking down a task into a series of workflows or processes, each with a specific step or action.\\n4. Goal-based decomposition: This involves breaking down a task into smaller subtasks that are focused on achieving a specific goal or outcome.\\n5. Task segmentation: This involves breaking down a task into smaller time segments, each with a specific duration or focus.\\n\\nThese approaches can be used alone or in combination to effectively break down a complex task into manageable parts. By using task decomposition, individuals and organizations can better understand the components of a task, identify potential challenges and obstacles, and develop strategies for completing the task more efficiently and effectively.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=RunnablePick(\"context\") | format_docs)\n",
    "    | rag_prompt_llama\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run\n",
    "print(question)\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whhat happens at CMU on 24th August every year\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, it seems that every year on August 24th, there is an event or activity happening at Carnegie Mellon University (CMU) related to the integration of reasoning and acting within large language models (LLMs). The event is called \"ReAct,\" which stands for \"Reasoning and Acting in LLMs.\"\\n\\nAccording to the context, ReAct integrates reasoning and acting within LLMs by extending the action space to be a combination of task-specific discrete actions and the language space. This allows LLMs to interact with the environment (e.g., use Wikipedia search API) and generate reasoning traces in natural language. The event may involve presentations, workshops, or other activities focused on the development and application of these technologies.\\n\\nUnfortunately, I cannot provide more information about the specific event happening on August 24th at CMU without further context or details.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Whhat happens at CMU on 24th August every year\"\n",
    "print(question)\n",
    "qa_chain.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmu_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
