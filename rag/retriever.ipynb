{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import chromadb\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnablePick\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "from chromadb.errors import InvalidDimensionException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_PATH = '/home/raj/nlp/cmu-rag/rag/chroma/txt/'\n",
    "embedding_name = 'llama2'\n",
    "persist_directory = DATABASE_PATH + embedding_name\n",
    "embedding = OllamaEmbeddings(model=embedding_name)\n",
    "\n",
    "vector_store = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt_llama = hub.pull(\"rlm/rag-prompt-llama\")\n",
    "rag_prompt_llama.messages\n",
    "\n",
    "\n",
    "\n",
    "prompt_message = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use as few words as possible and keep the answer concise. Do not mention the context in your response.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "rag_prompt_llama.messages[0].prompt.template = prompt_message\n",
    "\n",
    "llm = Ollama(model = 'llama2')\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt_llama\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw:\n",
      "\t The LTI PhD program requires 48 units of core courses.\n",
      "num_lines:\n",
      "\t 0\n",
      "processed:\n",
      "\t The LTI PhD program requires 48 units of core courses.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    answer = dict()\n",
    "\n",
    "    answer_raw = qa_chain.invoke(question)\n",
    "    answer[\"raw\"] = answer_raw\n",
    "    num_lines = answer_raw.count('\\n')\n",
    "    answer[\"num_lines\"] = num_lines\n",
    "    lines = answer_raw.split('\\n')\n",
    "    if num_lines == 1:\n",
    "        answer[\"processed\"] = lines[0] if \"i don't know\" not in lines[0].lower() else \"I do not know\"\n",
    "    else:\n",
    "        answer_lines = []\n",
    "        for line in lines:\n",
    "            if \"i don't know\" not in line.lower():\n",
    "                answer_lines.append(line)\n",
    "        answer[\"processed\"] = \" \".join(answer_lines)\n",
    "    \n",
    "    answers.append(answer)\n",
    "\n",
    "for answer in answers:\n",
    "    for k, v in answer.items():\n",
    "        print(f\"{k}:\\n\\t {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmu_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
